{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65db88f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T04:43:36.782771Z",
     "iopub.status.busy": "2022-10-08T04:43:36.782110Z",
     "iopub.status.idle": "2022-10-08T04:44:17.385986Z",
     "shell.execute_reply": "2022-10-08T04:44:17.384482Z"
    },
    "papermill": {
     "duration": 40.624257,
     "end_time": "2022-10-08T04:44:17.394394",
     "exception": false,
     "start_time": "2022-10-08T04:43:36.770137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vit-keras\r\n",
      "  Downloading vit_keras-0.1.0-py3-none-any.whl (24 kB)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from vit-keras) (1.7.3)\r\n",
      "Collecting validators\r\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /opt/conda/lib/python3.7/site-packages (from scipy->vit-keras) (1.21.6)\r\n",
      "Requirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from validators->vit-keras) (5.1.1)\r\n",
      "Building wheels for collected packages: validators\r\n",
      "  Building wheel for validators (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=b9ade3abe792e954d53719c6052bb04d3087f8de8b3286390ead2f35f252492a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\r\n",
      "Successfully built validators\r\n",
      "Installing collected packages: validators, vit-keras\r\n",
      "Successfully installed validators-0.20.0 vit-keras-0.1.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting pylibjpeg-libjpeg\r\n",
      "  Downloading pylibjpeg_libjpeg-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from pylibjpeg-libjpeg) (1.21.6)\r\n",
      "Installing collected packages: pylibjpeg-libjpeg\r\n",
      "Successfully installed pylibjpeg-libjpeg-1.3.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting python-gdcm\r\n",
      "  Downloading python_gdcm-3.0.19-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: python-gdcm\r\n",
      "Successfully installed python-gdcm-3.0.19\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install ../input/vitkerasprerequisites/validators-0.18.2-py3-none-any.whl\n",
    "# !pip install ../input/vitkerasprerequisites/vit_keras-0.1.0-py3-none-any.whl\n",
    "!pip install vit-keras\n",
    "\n",
    "# !pip install ../input/libjpeg-gdcm/pylibjpeg_libjpeg-1.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install pylibjpeg-libjpeg\n",
    "\n",
    "# !pip install ../input/libjpeg-gdcm/python_gdcm-3.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install python-gdcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d7c3a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T04:44:17.419695Z",
     "iopub.status.busy": "2022-10-08T04:44:17.419275Z",
     "iopub.status.idle": "2022-10-08T04:44:24.867916Z",
     "shell.execute_reply": "2022-10-08T04:44:24.866858Z"
    },
    "papermill": {
     "duration": 7.464433,
     "end_time": "2022-10-08T04:44:24.870709",
     "exception": false,
     "start_time": "2022-10-08T04:44:17.406276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pydicom \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "from vit_keras import vit, utils\n",
    "import tensorflow_addons as tfa\n",
    "import albumentations as A\n",
    "import ast\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "056505fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T04:44:24.889033Z",
     "iopub.status.busy": "2022-10-08T04:44:24.887934Z",
     "iopub.status.idle": "2022-10-08T04:44:24.893812Z",
     "shell.execute_reply": "2022-10-08T04:44:24.892614Z"
    },
    "papermill": {
     "duration": 0.016664,
     "end_time": "2022-10-08T04:44:24.895958",
     "exception": false,
     "start_time": "2022-10-08T04:44:24.879294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'train_df': '../input/rsna-2022-cervical-spine-fracture-detection/train.csv',\n",
    "    'test_df': '../input/rsna-2022-cervical-spine-fracture-detection/test.csv',\n",
    "    'batch_size': 128,\n",
    "    'lr': 1e-04,\n",
    "    'img_size': 258, \n",
    "    'vit_img_size': 256,\n",
    "    'epochs': 25,\n",
    "    'model_path': '../input/trial/best_model.h5'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405931f8",
   "metadata": {
    "papermill": {
     "duration": 0.00753,
     "end_time": "2022-10-08T04:44:24.911178",
     "exception": false,
     "start_time": "2022-10-08T04:44:24.903648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a315c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T04:44:24.936832Z",
     "iopub.status.busy": "2022-10-08T04:44:24.936482Z",
     "iopub.status.idle": "2022-10-08T04:44:26.893780Z",
     "shell.execute_reply": "2022-10-08T04:44:26.892093Z"
    },
    "papermill": {
     "duration": 1.981221,
     "end_time": "2022-10-08T04:44:26.900377",
     "exception": false,
     "start_time": "2022-10-08T04:44:24.919156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_paths</th>\n",
       "      <th>C_labels</th>\n",
       "      <th>patient_overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           img_paths               C_labels  \\\n",
       "0  ../input/rsna-2022-cervical-spine-fracture-det...  [0, 1, 0, 0, 0, 0, 0]   \n",
       "1  ../input/rsna-2022-cervical-spine-fracture-det...  [0, 1, 0, 0, 0, 0, 0]   \n",
       "2  ../input/rsna-2022-cervical-spine-fracture-det...  [0, 1, 0, 0, 0, 0, 0]   \n",
       "3  ../input/rsna-2022-cervical-spine-fracture-det...  [0, 1, 0, 0, 0, 0, 0]   \n",
       "4  ../input/rsna-2022-cervical-spine-fracture-det...  [0, 1, 0, 0, 0, 0, 0]   \n",
       "\n",
       "  patient_overall  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('../input/rsna-data/full_data.csv', dtype={\"patient_overall\": str})\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7077800",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T04:44:26.918937Z",
     "iopub.status.busy": "2022-10-08T04:44:26.918625Z",
     "iopub.status.idle": "2022-10-08T04:44:27.025791Z",
     "shell.execute_reply": "2022-10-08T04:44:27.024485Z"
    },
    "papermill": {
     "duration": 0.119799,
     "end_time": "2022-10-08T04:44:27.029661",
     "exception": false,
     "start_time": "2022-10-08T04:44:26.909862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 711601 entries, 0 to 711600\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   img_paths        711601 non-null  object\n",
      " 1   C_labels         711601 non-null  object\n",
      " 2   patient_overall  711601 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 16.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caec76a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T04:44:27.050253Z",
     "iopub.status.busy": "2022-10-08T04:44:27.049856Z",
     "iopub.status.idle": "2022-10-08T04:44:27.270850Z",
     "shell.execute_reply": "2022-10-08T04:44:27.269789Z"
    },
    "papermill": {
     "duration": 0.2344,
     "end_time": "2022-10-08T04:44:27.273467",
     "exception": false,
     "start_time": "2022-10-08T04:44:27.039067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df = data_df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "data_sample = data_df[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2683cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T04:44:27.291927Z",
     "iopub.status.busy": "2022-10-08T04:44:27.291599Z",
     "iopub.status.idle": "2022-10-08T04:44:27.525618Z",
     "shell.execute_reply": "2022-10-08T04:44:27.524613Z"
    },
    "papermill": {
     "duration": 0.245175,
     "end_time": "2022-10-08T04:44:27.527649",
     "exception": false,
     "start_time": "2022-10-08T04:44:27.282474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_paths</th>\n",
       "      <th>C_labels</th>\n",
       "      <th>patient_overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           img_paths               C_labels  \\\n",
       "0  ../input/rsna-2022-cervical-spine-fracture-det...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "1  ../input/rsna-2022-cervical-spine-fracture-det...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "2  ../input/rsna-2022-cervical-spine-fracture-det...  [0, 0, 0, 0, 1, 1, 0]   \n",
       "3  ../input/rsna-2022-cervical-spine-fracture-det...  [0, 0, 0, 0, 0, 0, 0]   \n",
       "4  ../input/rsna-2022-cervical-spine-fracture-det...  [0, 0, 0, 0, 0, 0, 1]   \n",
       "\n",
       "  patient_overall  \n",
       "0               0  \n",
       "1               0  \n",
       "2               1  \n",
       "3               0  \n",
       "4               1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    sample_train_df, sample_valid_df = train_test_split(data_sample, test_size=0.2, random_state=42, shuffle=True)\n",
    "    sample_train_df.reset_index(drop=True, inplace=True); sample_valid_df.reset_index(drop=True, inplace=True)\n",
    "    del data_sample, data_df; gc.collect()\n",
    "    sample_train_df.head()\n",
    "except: \n",
    "    data_df = pd.read_csv('../input/rsna-data/full_data.csv', dtype={\"patient_overall\": str})\n",
    "    data_df = data_df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "    data_sample = data_df[:15000]\n",
    "    sample_train_df, sample_valid_df = train_test_split(data_sample, test_size=0.2, random_state=42, shuffle=True)\n",
    "    sample_train_df.reset_index(drop=True, inplace=True); sample_valid_df.reset_index(drop=True, inplace=True)\n",
    "    del data_sample, data_df; gc.collect()\n",
    "sample_train_df.head()\n",
    "#sample_valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca1249f",
   "metadata": {
    "papermill": {
     "duration": 0.007888,
     "end_time": "2022-10-08T04:44:27.543867",
     "exception": false,
     "start_time": "2022-10-08T04:44:27.535979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8de337",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T04:44:27.561764Z",
     "iopub.status.busy": "2022-10-08T04:44:27.561398Z",
     "iopub.status.idle": "2022-10-08T04:44:27.573911Z",
     "shell.execute_reply": "2022-10-08T04:44:27.572790Z"
    },
    "papermill": {
     "duration": 0.024477,
     "end_time": "2022-10-08T04:44:27.576615",
     "exception": false,
     "start_time": "2022-10-08T04:44:27.552138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataPipeLine(Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        batch_size = cfg['batch_size'],\n",
    "        img_size = cfg['img_size'],\n",
    "        shuffle = True,\n",
    "        augments = True\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augments = augments\n",
    "        self.transforms = A.Compose([\n",
    "            A.GaussNoise(p=0.25),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.OneOf([\n",
    "                A.RandomCrop(width=self.img_size, height=self.img_size, p=1.0),\n",
    "                A.RandomResizedCrop(height=self.img_size, width=self.img_size, p = 1.0)\n",
    "            ], p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.2),\n",
    "            A.RandomRotate90(p=0.25)\n",
    "        ])\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "        return self.df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X, Y = [], []\n",
    "        batch = self.df[idx * self.batch_size: (idx+1)*self.batch_size]\n",
    "        for _, row in batch.iterrows():\n",
    "            #row = self.df.loc[i]\n",
    "            data = pydicom.dcmread(row['img_paths'])\n",
    "            img = pydicom.pixel_data_handlers.util.apply_voi_lut(data.pixel_array, data)\n",
    "            img = cv2.resize(img, (self.img_size, self.img_size)).reshape((self.img_size, self.img_size, 1))\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            img = img.astype(np.float32)\n",
    "            label = ast.literal_eval(row['C_labels'])\n",
    "            label.append(int(row['patient_overall']))\n",
    "            if self.augments:\n",
    "                img = self.transforms(image=img)['image']\n",
    "            X.append(img); Y.append(label)\n",
    "        return np.array(X), np.array(Y).astype(np.float32)\n",
    "#     def __call__(self):\n",
    "#         for idx in range(self.__len__()):\n",
    "#             yield self.__getitem__(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "661ebf5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T04:44:27.594886Z",
     "iopub.status.busy": "2022-10-08T04:44:27.594519Z",
     "iopub.status.idle": "2022-10-08T04:44:27.600047Z",
     "shell.execute_reply": "2022-10-08T04:44:27.598887Z"
    },
    "papermill": {
     "duration": 0.017232,
     "end_time": "2022-10-08T04:44:27.602253",
     "exception": false,
     "start_time": "2022-10-08T04:44:27.585021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_data = tf.data.Dataset.from_generator(\n",
    "#     DataPipeLine(sample_train_df),\n",
    "#     output_types=(tf.float32, tf.float32),\n",
    "#     output_shapes=((cfg['img_size'], cfg['img_size'], 1), (8,))\n",
    "# )\n",
    "\n",
    "# valid_data = tf.data.Dataset.from_generator(\n",
    "#     DataPipeLine(sample_valid_df),\n",
    "#     output_types=(tf.float32, tf.float32),\n",
    "#     output_shapes=((cfg['img_size'], cfg['img_size'], 1), (8,))\n",
    "# )\n",
    "\n",
    "# at = tf.data.AUTOTUNE\n",
    "# train_data = train_data.prefetch(at).batch(cfg['batch_size'])\n",
    "# valid_data = valid_data.prefetch(at).batch(cfg['batch_size'])\n",
    "train_data = DataPipeLine(sample_train_df)\n",
    "valid_data = DataPipeLine(sample_valid_df, augments = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39be4ee",
   "metadata": {
    "papermill": {
     "duration": 0.008026,
     "end_time": "2022-10-08T04:44:27.618588",
     "exception": false,
     "start_time": "2022-10-08T04:44:27.610562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d6bd258",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T04:44:27.636343Z",
     "iopub.status.busy": "2022-10-08T04:44:27.635999Z",
     "iopub.status.idle": "2022-10-08T04:45:34.465880Z",
     "shell.execute_reply": "2022-10-08T04:45:34.463946Z"
    },
    "papermill": {
     "duration": 66.841395,
     "end_time": "2022-10-08T04:45:34.468046",
     "exception": false,
     "start_time": "2022-10-08T04:44:27.626651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 04:44:27.748484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 04:44:27.852530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 04:44:27.853397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 04:44:27.854842: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-08 04:44:27.855229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 04:44:27.856214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 04:44:27.857140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 04:44:30.077195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 04:44:30.078120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 04:44:30.078821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-08 04:44:30.079434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-B_32_imagenet21k+imagenet2012.npz\n",
      "353255424/353253686 [==============================] - 58s 0us/step\n",
      "353263616/353253686 [==============================] - 58s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/vit_keras/utils.py:83: UserWarning: Resizing position embeddings from 12, 12 to 8, 8\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vision_transformer\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 3)       30        \n",
      "_________________________________________________________________\n",
      "vit-b32 (Functional)         (None, 768)               87466752  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                49216     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 87,519,846\n",
      "Trainable params: 87,518,182\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def ResNet_BiLSTM_Model(bilstm=256, weights = 'imagenet', augments=False):\n",
    "    input_tensor = keras.layers.Input(shape=(cfg['img_size'], cfg['img_size'], 1))\n",
    "    if augments:\n",
    "        x = keras.layers.experimental.preprocessing.RandomFlip('horizontal')(input_tensor)\n",
    "        x = keras.layers.experimental.preprocessing.RandomContrast(0.1, seed=0)(x)\n",
    "        x = keras.layers.experimental.preprocessing.RandomRotation(factor=0.25, seed=0)(x)\n",
    "        x = keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=0.1, seed=0)(x)\n",
    "        x = keras.layers.Conv2D(3, 3, padding='valid')(x)\n",
    "        x = keras.applications.ResNet50V2(weights=weights, include_top=False)(x)\n",
    "        \n",
    "    else:\n",
    "        x = keras.layers.Conv2D(3, 3, padding='valid')(input_tensor)\n",
    "        x = keras.applications.ResNet50V2(weights=weights, include_top=False)(x)\n",
    "    \n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Reshape((2048, 1))(x)\n",
    "    x = keras.layers.Bidirectional(keras.layers.LSTM(bilstm, return_sequences=False, activation='relu'))(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dense(8, activation='sigmoid')(x)\n",
    "    \n",
    "    return keras.models.Model(inputs=input_tensor, outputs=x)\n",
    "\n",
    "\n",
    "\n",
    "def ViT_Model():\n",
    "    Vit = vit.vit_b32(\n",
    "        image_size = (cfg['vit_img_size'], cfg['vit_img_size']),\n",
    "        activation = 'softmax',\n",
    "        pretrained = True,\n",
    "        include_top = False,\n",
    "        pretrained_top = False,\n",
    "        weights='imagenet21k+imagenet2012',\n",
    "        classes = 1000)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal', seed=0),\n",
    "#             tf.keras.layers.experimental.preprocessing.RandomFlip('vertical', seed=15),\n",
    "#             tf.keras.layers.experimental.preprocessing.RandomContrast(0.1, seed=30),\n",
    "#             tf.keras.layers.experimental.preprocessing.RandomTranslation(0.1, 0.1, seed=45),\n",
    "#             tf.keras.layers.experimental.preprocessing.RandomRotation(factor=0.25, seed=60),\n",
    "#             tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=0.1, seed=75),\n",
    "            tf.keras.layers.Conv2D(3, 3, padding='valid', input_shape=(cfg['img_size'], cfg['img_size'], 1)),\n",
    "            Vit,\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(64, activation = tfa.activations.gelu),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(8, 'sigmoid')\n",
    "        ], name = 'vision_transformer'\n",
    "    )\n",
    "    model.build(input_shape=(None, cfg['img_size'], cfg['img_size'], 1))\n",
    "    return model\n",
    "    \n",
    "\n",
    "def competiton_loss(y_true, y_pred):\n",
    "\n",
    "    competition_weights = {\n",
    "        '-' : tf.constant([1, 1, 1, 1, 1, 1, 1, 7], dtype=tf.float32),\n",
    "        '+' : tf.constant([2, 2, 2, 2, 2, 2, 2, 14], dtype=tf.float32)\n",
    "    }\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(tf.expand_dims(y_true, -1),tf.expand_dims(y_pred,-1))\n",
    "    weights  = y_true*competition_weights['+'] + (1-y_true)*competition_weights['-'] \n",
    "    \n",
    "    loss = tf.reduce_mean(tf.reduce_sum(loss * weights, axis=1)) / tf.reduce_sum(weights)\n",
    "    return loss\n",
    "\n",
    "#model = tf.keras.models.load_model(cfg['model_path'], custom_objects={'competiton_loss': competiton_loss}, compile=False)\n",
    "model = ViT_Model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43cf0e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T04:45:34.514859Z",
     "iopub.status.busy": "2022-10-08T04:45:34.514200Z",
     "iopub.status.idle": "2022-10-08T05:08:28.682108Z",
     "shell.execute_reply": "2022-10-08T05:08:28.680965Z"
    },
    "papermill": {
     "duration": 1374.195321,
     "end_time": "2022-10-08T05:08:28.685634",
     "exception": false,
     "start_time": "2022-10-08T04:45:34.490313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 04:45:37.232690: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 04:46:26.531218: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 362s 3s/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 2/25\n",
      "93/93 [==============================] - 252s 3s/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 3/25\n",
      "93/93 [==============================] - 196s 2s/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 4/25\n",
      "93/93 [==============================] - 184s 2s/step - loss: 0.0054 - val_loss: 0.0055\n",
      "Epoch 5/25\n",
      "93/93 [==============================] - 185s 2s/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 6/25\n",
      "93/93 [==============================] - 184s 2s/step - loss: 0.0053 - val_loss: 0.0054\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tfa.optimizers.RectifiedAdam(learning_rate=cfg['lr']),\n",
    "    loss= competiton_loss,\n",
    "    #metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='/kaggle/working/best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.9,\n",
    "    min_lr=1e-07,\n",
    "    patience=3,\n",
    "    verbose=0,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    min_delta=0,\n",
    "    monitor='val_loss',\n",
    "    restore_best_weights=True,\n",
    "    verbose=0,\n",
    "    mode='min',\n",
    "    baseline=None\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_data, \n",
    "    validation_data=valid_data,\n",
    "    epochs = cfg['epochs'],\n",
    "    callbacks=[es,reduce_lr,checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ffd4af1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T05:08:28.791540Z",
     "iopub.status.busy": "2022-10-08T05:08:28.790532Z",
     "iopub.status.idle": "2022-10-08T05:08:29.046061Z",
     "shell.execute_reply": "2022-10-08T05:08:29.045088Z"
    },
    "papermill": {
     "duration": 0.309964,
     "end_time": "2022-10-08T05:08:29.048196",
     "exception": false,
     "start_time": "2022-10-08T05:08:28.738232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4ca0ec4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T05:08:29.154767Z",
     "iopub.status.busy": "2022-10-08T05:08:29.154387Z",
     "iopub.status.idle": "2022-10-08T05:08:29.158731Z",
     "shell.execute_reply": "2022-10-08T05:08:29.157714Z"
    },
    "papermill": {
     "duration": 0.059368,
     "end_time": "2022-10-08T05:08:29.160889",
     "exception": false,
     "start_time": "2022-10-08T05:08:29.101521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b6c5cd",
   "metadata": {
    "papermill": {
     "duration": 0.051427,
     "end_time": "2022-10-08T05:08:29.263878",
     "exception": false,
     "start_time": "2022-10-08T05:08:29.212451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# References:\n",
    "1) Loss function: https://www.kaggle.com/code/vmuzhichenko/rsna-22-resnet-50-3d-train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1504.144328,
   "end_time": "2022-10-08T05:08:33.155041",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-08T04:43:29.010713",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
